---
name: Pull Request Validation

"on":
  pull_request:
    branches: [master, develop]
  # Manual trigger for testing workflow changes
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  checks: write
  statuses: write

env:
  DOTNET_VERSION: '9.0.x'

jobs:
  # Check if required secrets are configured
  check-secrets:
    name: Validate Required Secrets
    runs-on: ubuntu-latest
    outputs:
      secrets-available: ${{ steps.check.outputs.available }}
    steps:
      - name: Check required secrets
        id: check
        env:
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
          POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
        run: |
          missing_secrets=""

          # Check each required secret using environment variables
          if [ -z "$POSTGRES_PASSWORD" ]; then
            missing_secrets="$missing_secrets POSTGRES_PASSWORD"
          fi
          if [ -z "$POSTGRES_USER" ]; then
            missing_secrets="$missing_secrets POSTGRES_USER"
          fi
          if [ -z "$POSTGRES_DB" ]; then
            missing_secrets="$missing_secrets POSTGRES_DB"
          fi

          if [ -n "$missing_secrets" ]; then
            echo "‚ùå Required secrets are missing:$missing_secrets"
            echo ""
            echo "Please configure the following secrets in your repository:"
            for secret in $missing_secrets; do
              echo "  - $secret"
            done
            echo ""
            echo "üìñ Go to Settings ‚Üí Secrets and variables ‚Üí Actions to add them"
            echo "available=false" >> $GITHUB_OUTPUT
            exit 1
          else
            echo "‚úÖ All required secrets are configured"
            echo "available=true" >> $GITHUB_OUTPUT
          fi

  # Job 1: Code Quality Checks
  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    needs: check-secrets

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
          POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
          POSTGRES_HOST_AUTH_METHOD: md5
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Check Database Configuration
        run: echo "‚úÖ GitHub secrets configured (enforced by check-secrets)"

      - name: Check Keycloak Configuration
        env:
          KEYCLOAK_ADMIN_PASSWORD: ${{ secrets.KEYCLOAK_ADMIN_PASSWORD }}
        run: |
          echo "üîç Checking Keycloak configuration..."
          if [ -z "$KEYCLOAK_ADMIN_PASSWORD" ]; then
            echo "‚ÑπÔ∏è  KEYCLOAK_ADMIN_PASSWORD secret not configured - Keycloak is optional"
            echo "üí° To enable Keycloak authentication features, configure the secret in:"
            echo "   Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí KEYCLOAK_ADMIN_PASSWORD"
            echo "üîÑ Tests will continue without Keycloak-dependent features"
          else
            echo "‚úÖ Keycloak secrets configured - authentication features enabled"
          fi

      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Restore dependencies
        run: dotnet restore MeAjudaAi.sln

      - name: Build solution
        run: dotnet build MeAjudaAi.sln --configuration Release --no-restore

      - name: Wait for PostgreSQL to be ready
        env:
          PGPASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
        run: |
          echo "üîÑ Waiting for PostgreSQL to be ready..."
          echo "Debug: POSTGRES_USER=$POSTGRES_USER"
          echo "Debug: Checking PostgreSQL availability..."

          counter=1
          max_attempts=60

          while [ $counter -le $max_attempts ]; do
            if pg_isready -h localhost -p 5432 -U "$POSTGRES_USER"; then
              echo "‚úÖ PostgreSQL is ready!"
              break
            fi
            echo "Waiting for PostgreSQL... ($counter/$max_attempts)"
            sleep 3
            counter=$((counter + 1))
          done

          # Check if we exited the loop due to timeout
          if ! pg_isready -h localhost -p 5432 -U "$POSTGRES_USER"; then
            echo "‚ùå PostgreSQL failed to become ready within 180 seconds"
            echo "Debug: Checking PostgreSQL logs..."
            echo "Service container id: ${{ job.services.postgres.id }}"
            docker logs "${{ job.services.postgres.id }}" || echo "Could not get PostgreSQL logs"
            exit 1
          fi

      - name: Run tests with coverage
        env:
          ASPNETCORE_ENVIRONMENT: Testing
          # Pre-built connection string (optional, takes precedence if available)
          DB_CONNECTION_STRING: ${{ secrets.DB_CONNECTION_STRING }}
          # PostgreSQL connection for CI
          EXTERNAL_POSTGRES_HOST: localhost
          EXTERNAL_POSTGRES_PORT: 5432
          MEAJUDAAI_DB_HOST: localhost
          MEAJUDAAI_DB_PORT: 5432
          MEAJUDAAI_DB_PASS: ${{ secrets.POSTGRES_PASSWORD }}
          MEAJUDAAI_DB_USER: ${{ secrets.POSTGRES_USER }}
          MEAJUDAAI_DB: ${{ secrets.POSTGRES_DB }}
          # Legacy environment variables for compatibility
          DB_HOST: localhost
          DB_PORT: 5432
          DB_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          DB_USERNAME: ${{ secrets.POSTGRES_USER }}
          DB_NAME: ${{ secrets.POSTGRES_DB }}
          # Keycloak settings
          KEYCLOAK_ADMIN_PASSWORD: ${{ secrets.KEYCLOAK_ADMIN_PASSWORD }}
        run: |
          set -euo pipefail
          echo "üß™ Executando testes com cobertura consolidada..."

          # Function to escape single quotes in PostgreSQL connection string values
          escape_single_quotes() {
            echo "$1" | sed "s/'/''/g"
          }

          # Build .NET connection string from PostgreSQL secrets with proper quoting
          # Check if a pre-built connection string secret exists first
          if [ -n "${DB_CONNECTION_STRING:-}" ]; then
            export ConnectionStrings__DefaultConnection="$DB_CONNECTION_STRING"
            echo "‚úÖ Using pre-built connection string from DB_CONNECTION_STRING secret"
          else
            # Build connection string with proper Npgsql quoting for special characters
            ESCAPED_DB=$(escape_single_quotes "$MEAJUDAAI_DB")
            ESCAPED_USER=$(escape_single_quotes "$MEAJUDAAI_DB_USER")
            ESCAPED_PASS=$(escape_single_quotes "$MEAJUDAAI_DB_PASS")

            DB_CONN_STR="Host=localhost;Port=5432;Database='$ESCAPED_DB'"
            DB_CONN_STR="${DB_CONN_STR};Username='$ESCAPED_USER';Password='$ESCAPED_PASS'"
            export ConnectionStrings__DefaultConnection="$DB_CONN_STR"
            echo "‚úÖ Built connection string from PostgreSQL secrets with proper quoting"
          fi

          # Test database connection first
          echo "Testing database connection..."
          PGPASSWORD="$MEAJUDAAI_DB_PASS" \
            psql -h localhost \
                 -U "$MEAJUDAAI_DB_USER" \
                 -d "$MEAJUDAAI_DB" \
                 -c "SELECT 1;" || {
            echo "‚ùå Database connection failed ‚Äî aborting workflow"
            echo "üí° Ensure PostgreSQL service is running and secrets are configured:"
            echo "   - POSTGRES_PASSWORD, POSTGRES_USER, POSTGRES_DB"
            echo "üîÑ Integration tests require database connectivity to validate changes"
            exit 1
          }

          # Remove any existing coverage data
          rm -rf ./coverage
          mkdir -p ./coverage

          echo "üß™ Running unit tests with coverage for all modules..."

          # Define modules for coverage testing
          # FORMAT: "ModuleName:path/to/module/tests/"
          # TO ADD NEW MODULE: Add line like "Orders:src/Modules/Orders/MeAjudaAi.Modules.Orders.Tests/"
          # See docs/adding-new-modules.md for complete instructions
          MODULES=(
            "Users:src/Modules/Users/MeAjudaAi.Modules.Users.Tests/"
            # Future modules can be added here:
            # "Orders:src/Modules/Orders/MeAjudaAi.Modules.Orders.Tests/"
            # "Payments:src/Modules/Payments/MeAjudaAi.Modules.Payments.Tests/"
          )

          # Run unit tests for each module with coverage
          for module_info in "${MODULES[@]}"; do
            IFS=':' read -r module_name module_path <<< "$module_info"

            if [ -d "$module_path" ]; then
              echo "Running $module_name module unit tests with coverage..."

              # Create specific output directory for this module
              MODULE_COVERAGE_DIR="./coverage/${module_name,,}"
              mkdir -p "$MODULE_COVERAGE_DIR"

              # Run tests with simplified coverage collection - UNIT TESTS ONLY
              INCLUDE_FILTER="[MeAjudaAi.Modules.${module_name}.*]*"
              EXCLUDE_FILTER="[*.Tests]*,[*Test*]*,[testhost]*"
              dotnet test "$module_path" \
                --configuration Release \
                --no-build \
                --verbosity normal \
                --filter "FullyQualifiedName!~Integration&FullyQualifiedName!~Infrastructure" \
                --collect:"XPlat Code Coverage" \
                --results-directory "$MODULE_COVERAGE_DIR" \
                --logger "trx;LogFileName=${module_name,,}-test-results.trx" \
                -- DataCollectionRunSettings.DataCollectors.DataCollector.Configuration.Format=opencover \
                -- DataCollectionRunSettings.DataCollectors.DataCollector.Configuration.Include="$INCLUDE_FILTER" \
                -- DataCollectionRunSettings.DataCollectors.DataCollector.Configuration.Exclude="$EXCLUDE_FILTER"

              # Find and rename the coverage file to a predictable name
              if [ -d "$MODULE_COVERAGE_DIR" ]; then
                COVERAGE_FILE=$(find "$MODULE_COVERAGE_DIR" -name "coverage.opencover.xml" -type f | head -1)
                if [ -f "$COVERAGE_FILE" ]; then
                  cp "$COVERAGE_FILE" "$MODULE_COVERAGE_DIR/${module_name,,}.opencover.xml"
                  echo "‚úÖ Coverage file created: $MODULE_COVERAGE_DIR/${module_name,,}.opencover.xml"
                else
                  echo "‚ö†Ô∏è  Coverage file not found for $module_name module"
                  find "$MODULE_COVERAGE_DIR" -name "*.xml" -type f | head -5
                fi
              fi
            else
              echo "‚ö†Ô∏è  Module $module_name tests not found at $module_path - skipping"
            fi
          done

          echo "üß™ Running system tests without coverage collection..."

          # Define system tests (no coverage)
          SYSTEM_TESTS=(
            "Architecture:tests/MeAjudaAi.Architecture.Tests/"
            "Integration:tests/MeAjudaAi.Integration.Tests/"
            "Shared:tests/MeAjudaAi.Shared.Tests/"
            # "E2E:tests/MeAjudaAi.E2E.Tests/"  # Uncomment when E2E tests are ready
          )

          # Run system tests without coverage
          for test_info in "${SYSTEM_TESTS[@]}"; do
            IFS=':' read -r test_name test_path <<< "$test_info"

            if [ -d "$test_path" ]; then
              echo "Running $test_name tests (no coverage)..."
              dotnet test "$test_path" \
                --configuration Release \
                --no-build \
                --verbosity normal \
                --logger "trx;LogFileName=${test_name,,}-test-results.trx"
            else
              echo "‚ö†Ô∏è  $test_name tests not found at $test_path - skipping"
            fi
          done

          echo "‚úÖ Todos os testes executados com sucesso"

      - name: Validate namespace reorganization
        run: |
          echo "üîç Validating namespace reorganization..."
          if grep -R -nE '^[[:space:]]*using[[:space:]]+MeAjudaAi\.Shared\.Common;' -- src/ \
              2>/dev/null; then
            echo "‚ùå Found old namespace imports"
            exit 1
          else
            echo "‚úÖ Conformidade com namespaces validada"
          fi

      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-reports
          path: coverage/**
          if-no-files-found: ignore

      - name: Upload Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: "**/*.trx"
          if-no-files-found: ignore

      - name: List Coverage Files (Debug)
        run: |
          echo "üîç Listing coverage files for debugging..."
          echo "Coverage directory structure:"
          find ./coverage -type f 2>/dev/null | head -20 || echo "No files found in coverage directory"
          echo ""
          echo "OpenCover XML files:"
          find ./coverage -name "*.opencover.xml" -type f 2>/dev/null || echo "No .opencover.xml files found"
          echo ""
          echo "Any XML files:"
          find ./coverage -name "*.xml" -type f 2>/dev/null || echo "No XML files found"
          echo ""
          echo "Coverage directory contents:"
          ls -la ./coverage/ 2>/dev/null || echo "Coverage directory not found"
          echo ""
          echo "Checking for coverage.xml files:"
          find ./coverage -name "coverage.xml" -type f 2>/dev/null || echo "No coverage.xml files found"

      - name: Fix Coverage Files (if needed)
        run: |
          echo "üîß Attempting to fix coverage file locations and names..."

          # Find any coverage.xml files and rename them to .opencover.xml
          find ./coverage -name "coverage.xml" -type f | while read -r file; do
            dir=$(dirname "$file")
            module=$(basename "$dir")
            new_file="$dir/$module.opencover.xml"
            echo "Copying $file to $new_file"
            cp "$file" "$new_file"
          done

          # Find coverage files in nested directories and copy to module directories
          find ./coverage -name "coverage.opencover.xml" -type f | while read -r file; do
            # Get the module directory (should be like ./coverage/users/)
            module_dir=$(echo "$file" | sed 's|coverage/\([^/]*\)/.*|coverage/\1|')
            module_name=$(basename "$module_dir")
            target_file="$module_dir/$module_name.opencover.xml"

            if [ "$file" != "$target_file" ]; then
              echo "Copying $file to $target_file"
              cp "$file" "$target_file" 2>/dev/null || true
            fi
          done

          echo "Coverage files after processing:"
          find ./coverage -name "*.opencover.xml" -type f 2>/dev/null || echo "Still no .opencover.xml files found"

      - name: Code Coverage Summary
        id: coverage_opencover
        continue-on-error: true
        uses: irongut/CodeCoverageSummary@v1.3.0
        with:
          filename: 'coverage/**/*.opencover.xml'
          badge: true
          fail_below_min: false
          format: markdown
          hide_branch_rate: false
          hide_complexity: false
          indicators: true
          output: both
          thresholds: '70 85'

      - name: Alternative Coverage Summary (if opencover fails)
        id: coverage_fallback
        if: ${{ always() && steps.coverage_opencover.outcome != 'success' }}
        uses: irongut/CodeCoverageSummary@v1.3.0
        with:
          filename: 'coverage/**/*.xml'
          badge: true
          fail_below_min: false
          format: markdown
          hide_branch_rate: false
          hide_complexity: false
          indicators: true
          output: both
          thresholds: '70 85'
        continue-on-error: true

      - name: Display Coverage Percentages
        if: always()
        run: |
          echo "üìä CODE COVERAGE SUMMARY"
          echo "========================"
          echo ""
          # Look for coverage files and extract basic statistics
          for coverage_file in $(find ./coverage -name "*.opencover.xml" -o -name "*.xml" | head -5); do
            if [ -f "$coverage_file" ]; then
              echo "üìÑ Coverage file: $coverage_file"
              # Extract line coverage using grep/awk if available
              if command -v awk >/dev/null 2>&1; then
                # Try to extract coverage statistics from OpenCover XML
                COVERAGE_LINE_ATTR='sequenceCoverage="[^"]*"'
                COVERAGE_BRANCH_ATTR='branchCoverage="[^"]*"'
                lines_covered=$(grep -o "$COVERAGE_LINE_ATTR" "$coverage_file" 2>/dev/null | \
                  head -1 | grep -o '[0-9.]*' || echo "N/A")
                branch_covered=$(grep -o "$COVERAGE_BRANCH_ATTR" "$coverage_file" 2>/dev/null | \
                  head -1 | grep -o '[0-9.]*' || echo "N/A")
                if [ "$lines_covered" != "N/A" ]; then
                  echo "  üìà Line Coverage: ${lines_covered}%"
                fi
                if [ "$branch_covered" != "N/A" ]; then
                  echo "  üåø Branch Coverage: ${branch_covered}%"
                fi
              fi
              echo ""
            fi
          done

          echo "üí° For detailed coverage report, check the 'Code Coverage Summary' step above"
          echo "üéØ Minimum thresholds: 70% (warning) / 85% (good)"

      - name: Add Coverage PR Comment
        uses: marocchino/sticky-pull-request-comment@v2
        if: github.event_name == 'pull_request'
        with:
          recreate: true
          header: coverage-report
          message: |
            ## üìä Code Coverage Report

            ${{ steps.coverage_opencover.outputs.summary || steps.coverage_fallback.outputs.summary }}

            ### üìà Coverage Details
            - **Coverage badges**: ${{ steps.coverage_opencover.outputs.badge ||
              steps.coverage_fallback.outputs.badge }}
            - **Minimum threshold**: 70% (warning) / 85% (good)
            - **Report format**: OpenCover XML with detailed metrics

            ### üìã Coverage Analysis
            - **Line Coverage**: Shows percentage of code lines executed during tests
            - **Branch Coverage**: Shows percentage of code branches/conditions tested
            - **Complexity**: Code complexity metrics for maintainability

            ### üéØ Quality Gates
            - ‚úÖ **Pass**: Coverage ‚â• 85%
            - ‚ö†Ô∏è **Warning**: Coverage 70-84%
            - ‚ùå **Fail**: Coverage < 70%

            ### üìÅ Artifacts
            - **Coverage reports**: Available in workflow artifacts
            - **Test results**: TRX files with detailed test execution data

            *This comment is updated automatically on each push to track coverage trends.*

      - name: Validate Coverage Thresholds
        if: always()
        run: |
          echo "üéØ VALIDATING COVERAGE THRESHOLDS"
          echo "================================="

          # Check step outcomes first
          primary_success="${{ steps.coverage_opencover.outcome }}"
          fallback_success="${{ steps.coverage_fallback.outcome }}"

          echo "Debug: Primary coverage outcome: $primary_success"
          echo "Debug: Fallback coverage outcome: $fallback_success"

          # Get coverage percentages (if available)
          primary_line_rate="${{ steps.coverage_opencover.outputs.line-rate }}"
          fallback_line_rate="${{ steps.coverage_fallback.outputs.line-rate }}"

          echo "Debug: Primary line rate: $primary_line_rate"
          echo "Debug: Fallback line rate: $fallback_line_rate"

          # Determine which coverage value to use
          coverage_rate=""
          if [ "$primary_success" = "success" ] && [ -n "$primary_line_rate" ]; then
            coverage_rate="$primary_line_rate"
            echo "üìä Using primary coverage: ${coverage_rate}%"
          elif [ "$fallback_success" = "success" ] && [ -n "$fallback_line_rate" ]; then
            coverage_rate="$fallback_line_rate"
            echo "üìä Using fallback coverage: ${coverage_rate}%"
          fi

          # Validate coverage against threshold
          if [ -n "$coverage_rate" ]; then
            # Convert to integer for comparison (remove decimal part)
            coverage_int=$(echo "$coverage_rate" | cut -d'.' -f1)

            if [ "$coverage_int" -ge 70 ]; then
              echo "‚úÖ Coverage analysis completed successfully"
              echo "üìä Coverage thresholds met: ${coverage_rate}% (‚â•70%)"
            else
              echo "‚ùå Coverage below minimum threshold: ${coverage_rate}% (required: ‚â•70%)"
              echo "üí° Check the 'Code Coverage Summary' step for detailed information"

              # Only fail in strict mode
              if [ "${STRICT_COVERAGE:-true}" = "true" ]; then
                echo "üö´ STRICT MODE: Failing pipeline due to insufficient coverage"
                exit 1
              else
                echo "‚ö†Ô∏è  LENIENT MODE: Continuing despite coverage issues"
              fi
            fi
          else
            echo "‚ùå Coverage analysis failed - no coverage data available"
            echo "üí° Check the 'Code Coverage Summary' step for errors"

            # Only fail in strict mode
            if [ "${STRICT_COVERAGE:-true}" = "true" ]; then
              echo "üö´ STRICT MODE: Failing pipeline due to coverage analysis failure"
              exit 1
            else
              echo "‚ö†Ô∏è  LENIENT MODE: Continuing despite coverage analysis issues"
            fi
          fi

  # Job 2: Security Scan (Consolidated)
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Restore dependencies
        run: dotnet restore MeAjudaAi.sln

      - name: Run Security Audit
        run: dotnet list package --vulnerable --include-transitive

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: OSV-Scanner (fail on HIGH/CRITICAL)
        run: |
          echo "üîç Installing OSV-Scanner..."
          # Install OSV-Scanner with pinned version for reproducibility
          OSV_VERSION="v1.8.3"
          OSV_URL="https://github.com/google/osv-scanner/releases/download/${OSV_VERSION}"
          curl -sSfL "${OSV_URL}/osv-scanner_linux_amd64" -o osv-scanner
          chmod +x osv-scanner

          echo "OSV-Scanner version and help:"
          ./osv-scanner --version || echo "Version command failed"
          ./osv-scanner scan --help | head -20 || echo "Help command failed"

          echo "üîç Running vulnerability scan..."
          # Run OSV-Scanner and capture exit code
          osv_exit_code=0
          ./osv-scanner scan --recursive --skip-git . || osv_exit_code=$?

          if [ $osv_exit_code -eq 0 ]; then
            echo "‚úÖ No vulnerabilities found"
          else
            echo "‚ö†Ô∏è OSV-Scanner found vulnerabilities (exit code: $osv_exit_code)"
            echo "üìÑ Running detailed scan for analysis..."

            # Run again with JSON output for detailed analysis
            ./osv-scanner scan --recursive --skip-git --format json . > osv-results.json || true

            if [ -f osv-results.json ]; then
              # Count HIGH/CRITICAL by CVSS (>=7.0) with safe parsing and textual severity mapping
              HIGH_OR_CRIT=$(
                jq -r '
                  # Function to safely convert severity scores to numbers
                  def safe_score_to_number:
                    if type == "number" then .
                    elif type == "string" then
                      (tonumber? // (
                        (. | ascii_upcase) as $upper
                        | if $upper == "CRITICAL" then 9
                          elif $upper == "HIGH" then 7
                          elif $upper == "MEDIUM" then 5
                          elif $upper == "LOW" then 3
                          else 0
                          end
                      ))
                    else 0
                    end;

                  [.results[]?.packages[]?.vulnerabilities[]?
                    | ( [(.severity // [])[]?.score? | safe_score_to_number] | max // 0 )
                    | select(. >= 7.0)
                  ] | length
                ' osv-results.json 2>/dev/null
              )

              if [ "${HIGH_OR_CRIT:-0}" -gt 0 ]; then
                echo "‚ùå Found $HIGH_OR_CRIT HIGH/CRITICAL vulnerabilities"
                echo "üìã First 10 vulnerabilities found:"
                # Use inline jq program to display vulnerability summary
                jq -r '.results[]?.packages[]?.vulnerabilities[]? |
                  "- \(.id): \(.summary // "No summary")"' \
                  osv-results.json 2>/dev/null | head -10
                echo ""
                echo "üö´ Security scan failed - vulnerabilities detected"
                echo "üí° Please review and fix vulnerabilities before merging"

                # Fail the workflow
                exit 1
              else
                echo "‚úÖ No HIGH/CRITICAL vulnerabilities found"
                # Count total vulnerabilities for info
                TOTAL_VULNS=$(jq -r '.results[]?.packages[]?.vulnerabilities[]? | .id' \
                  osv-results.json 2>/dev/null | wc -l)
                if [ "$TOTAL_VULNS" -gt 0 ]; then
                  echo "‚ÑπÔ∏è  Found $TOTAL_VULNS low/medium severity vulnerabilities (ignored)"
                fi
              fi
            else
              echo "‚ùå OSV-Scanner failed but no results file generated"
              exit 1
            fi
          fi

      - name: Secret Detection with TruffleHog
        if: ${{ github.event_name == 'pull_request' }}
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: ${{ github.event.pull_request.base.ref }}
          head: ${{ github.event.pull_request.head.sha }}
          extra_args: --debug --only-verified
  # Job 3: Markdown Link Validation (Simplified)
  markdown-link-check:
    name: Validate Markdown Links
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Cache lychee results
        uses: actions/cache@v4
        with:
          path: .lycheecache
          key: lychee-${{ runner.os }}-${{ hashFiles('**/*.md','lychee.toml') }}
          restore-keys: |
            lychee-${{ runner.os }}-

      - name: Check markdown links with lychee
        uses: lycheeverse/lychee-action@v1.10.0
        with:
          # Use simplified configuration for reliability
          args: >-
            --config lychee.toml
            --no-progress
            --cache
            --max-cache-age 1d
            "docs/**/*.md"
            "README.md"
          # Don't fail the entire pipeline on link check failures
          fail: false
          jobSummary: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Report link check results
        if: always()
        run: |
          echo "üìã Link validation completed (non-blocking)"
          echo "‚ÑπÔ∏è  Check job summary for detailed results"

  # Job 4: Simple YAML Validation (Quiet)
  yaml-validation:
    name: YAML Syntax Check
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install yamllint
        run: python3 -m pip install yamllint

      - name: Validate workflow files only
        run: |
          echo "üîç Validating critical YAML files..."
          if ! python3 -m yamllint -c .yamllint.yml .github/workflows/; then
            echo "‚ùå YAML validation failed"
            echo "‚ÑπÔ∏è  Check yamllint output above for details"
            exit 1
          fi
          echo "‚úÖ YAML validation completed"
