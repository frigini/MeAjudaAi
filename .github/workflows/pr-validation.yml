---
name: Pull Request Validation

"on":
  pull_request:
    branches: [master, develop]
  # Manual trigger for testing workflow changes
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  checks: write
  statuses: write

env:
  DOTNET_VERSION: '10.0.x'
  # CRITICAL: Set STRICT_COVERAGE: true before merging to main
  # This enforces 80% minimum coverage threshold (lines 785, 810)
  # Current bypass is TEMPORARY for development only
  # TODO: Enable STRICT_COVERAGE when overall coverage ‚â• 90% (Sprint 2 milestone)
  #       Tracking: https://github.com/frigini/MeAjudaAi/issues/33
  #       References: docs/testing/code-coverage-guide.md#L297-L313
  # Re-enable when overall coverage reaches 90% (Sprint 2 milestone)
  STRICT_COVERAGE: false
  # PostgreSQL configuration (DRY principle - single source of truth)
  # Fallback credentials: Only used in fork/local dev; main repo requires secrets
  POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD || 'test123' }}
  POSTGRES_USER: ${{ secrets.POSTGRES_USER || 'postgres' }}
  POSTGRES_DB: ${{ secrets.POSTGRES_DB || 'meajudaai_test' }}

jobs:
  # Job 1: Code Quality Checks
  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgis/postgis:16-3.4
        env:
          # Using workflow-level environment variables (defined at top)
          POSTGRES_PASSWORD: ${{ env.POSTGRES_PASSWORD }}
          POSTGRES_USER: ${{ env.POSTGRES_USER }}
          POSTGRES_DB: ${{ env.POSTGRES_DB }}
          POSTGRES_HOST_AUTH_METHOD: md5
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      azurite:
        image: mcr.microsoft.com/azure-storage/azurite:latest
        ports:
          - 10000:10000
          - 10001:10001
          - 10002:10002

    steps:
      - name: Checkout code
        uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Setup .NET
        uses: actions/setup-dotnet@v5
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Validate Secrets Configuration
        run: |
          echo "Using PostgreSQL credentials with fallback defaults"
          echo "POSTGRES_USER: ${{ env.POSTGRES_USER }}"
          echo "POSTGRES_DB: ${{ env.POSTGRES_DB }}"
          echo "POSTGRES_PASSWORD: [REDACTED]"

          echo "Database configuration validated"

      - name: Check Keycloak Configuration
        env:
          KEYCLOAK_ADMIN_PASSWORD: ${{ secrets.KEYCLOAK_ADMIN_PASSWORD }}
        run: |
          echo "üîç Checking Keycloak configuration..."
          if [ -z "$KEYCLOAK_ADMIN_PASSWORD" ]; then
            echo "‚ÑπÔ∏è  KEYCLOAK_ADMIN_PASSWORD secret not configured - Keycloak is optional"
            echo "üí° To enable Keycloak authentication features, configure the secret in:"
            echo "   Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí KEYCLOAK_ADMIN_PASSWORD"
            echo "üîÑ Tests will continue without Keycloak-dependent features"
          else
            echo "‚úÖ Keycloak secrets configured - authentication features enabled"
          fi

      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: üîß Restore dependencies
        run: dotnet restore MeAjudaAi.sln

      - name: Build solution
        run: dotnet build MeAjudaAi.sln --configuration Release --no-restore

      - name: Wait for PostgreSQL to be ready
        env:
          PGPASSWORD: ${{ env.POSTGRES_PASSWORD }}
          POSTGRES_USER: ${{ env.POSTGRES_USER }}
        run: |
          echo "üîÑ Waiting for PostgreSQL to be ready..."
          echo "Debug: POSTGRES_USER=$POSTGRES_USER"
          echo "Debug: Checking PostgreSQL availability..."

          counter=1
          max_attempts=60

          while [ $counter -le $max_attempts ]; do
            if pg_isready -h localhost -p 5432 -U "$POSTGRES_USER"; then
              echo "‚úÖ PostgreSQL is ready!"
              break
            fi
            echo "Waiting for PostgreSQL... ($counter/$max_attempts)"
            sleep 3
            counter=$((counter + 1))
          done

          # Check if we exited the loop due to timeout
          if ! pg_isready -h localhost -p 5432 -U "$POSTGRES_USER"; then
            echo "‚ùå PostgreSQL failed to become ready within 180 seconds"
            echo "Debug: Checking PostgreSQL logs..."
            echo "Service container id: ${{ job.services.postgres.id }}"
            docker logs "${{ job.services.postgres.id }}" || echo "Could not get PostgreSQL logs"
            exit 1
          fi

      - name: Setup PostgreSQL connection
        id: db
        uses: ./.github/actions/setup-postgres-connection
        with:
          postgres-host: localhost
          postgres-port: 5432
          postgres-db: ${{ env.POSTGRES_DB }}
          postgres-user: ${{ env.POSTGRES_USER }}
          postgres-password: ${{ env.POSTGRES_PASSWORD }}

      - name: Run Unit Tests
        env:
          ASPNETCORE_ENVIRONMENT: Testing
          # Pre-built connection string (optional, takes precedence if available)
          DB_CONNECTION_STRING: ${{ secrets.DB_CONNECTION_STRING }}
          # PostgreSQL connection for CI
          EXTERNAL_POSTGRES_HOST: localhost
          EXTERNAL_POSTGRES_PORT: 5432
          MEAJUDAAI_DB_HOST: localhost
          MEAJUDAAI_DB_PORT: 5432
          MEAJUDAAI_DB_PASS: ${{ env.POSTGRES_PASSWORD }}
          MEAJUDAAI_DB_USER: ${{ env.POSTGRES_USER }}
          MEAJUDAAI_DB: ${{ env.POSTGRES_DB }}
          # Legacy environment variables for compatibility
          DB_HOST: localhost
          DB_PORT: 5432
          DB_PASSWORD: ${{ env.POSTGRES_PASSWORD }}
          DB_USERNAME: ${{ env.POSTGRES_USER }}
          DB_NAME: ${{ env.POSTGRES_DB }}
          # Keycloak settings
          KEYCLOAK_ADMIN_PASSWORD: ${{ secrets.KEYCLOAK_ADMIN_PASSWORD }}
          # Azure Storage (Azurite emulator)
          # ‚ö†Ô∏è TEST CREDENTIALS ONLY - These are the standard Azurite local emulator credentials
          # These are intentionally public and documented at:
          # https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azurite#well-known-storage-account-and-key
          AZURE_STORAGE_CONNECTION_STRING: "DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://localhost:10000/devstoreaccount1;"
          AzureStorage__ConnectionString: "DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://localhost:10000/devstoreaccount1;"
          # Map connection strings to .NET configuration using double underscore
          ConnectionStrings__DefaultConnection: ${{ steps.db.outputs.connection-string }}
          ConnectionStrings__Users: ${{ steps.db.outputs.connection-string }}
          ConnectionStrings__Search: ${{ steps.db.outputs.connection-string }}
          ConnectionStrings__meajudaai-db: ${{ steps.db.outputs.connection-string }}
        run: |
          set -euo pipefail
          echo "üß™ Executando testes com cobertura consolidada..."

          # Function to escape single quotes in PostgreSQL connection string values
          escape_single_quotes() {
            echo "$1" | sed "s/'/''/g"
          }

          # Build .NET connection string from PostgreSQL secrets with proper quoting
          # Check if a pre-built connection string secret exists first
          if [ -n "${DB_CONNECTION_STRING:-}" ]; then
            export ConnectionStrings__DefaultConnection="$DB_CONNECTION_STRING"
            echo "‚úÖ Using pre-built connection string from DB_CONNECTION_STRING secret"
          else
            # Build connection string with proper Npgsql quoting for special characters
            ESCAPED_DB=$(escape_single_quotes "$MEAJUDAAI_DB")
            ESCAPED_USER=$(escape_single_quotes "$MEAJUDAAI_DB_USER")
            ESCAPED_PASS=$(escape_single_quotes "$MEAJUDAAI_DB_PASS")

            DB_CONN_STR="Host=localhost;Port=5432;Database='$ESCAPED_DB'"
            DB_CONN_STR="${DB_CONN_STR};Username='$ESCAPED_USER';Password='$ESCAPED_PASS'"
            export ConnectionStrings__DefaultConnection="$DB_CONN_STR"
            echo "‚úÖ Built connection string from PostgreSQL secrets with proper quoting"
          fi

          # Test database connection first
          echo "Testing database connection..."
          PGPASSWORD="$MEAJUDAAI_DB_PASS" \
            psql -h localhost \
                 -U "$MEAJUDAAI_DB_USER" \
                 -d "$MEAJUDAAI_DB" \
                 -c "SELECT 1;" || {
            echo "‚ùå Database connection failed ‚Äî aborting workflow"
            echo "üí° Ensure PostgreSQL service is running and secrets are configured:"
            echo "   - POSTGRES_PASSWORD, POSTGRES_USER, POSTGRES_DB"
            echo "üîÑ Integration tests require database connectivity to validate changes"
            exit 1
          }

          # Remove any existing coverage data
          rm -rf ./coverage
          mkdir -p ./coverage

          echo "üß™ Running unit tests with coverage for all modules..."

          # Define modules for coverage testing
          # STRATEGY: Comprehensive coverage for Domain, Application, and critical Shared/ApiService layers
          # - Domain/Application: Core business logic (80-100% target)
          # - Shared/ApiService: Reusable infrastructure, middlewares, extensions (60-80% target)
          # - Excluded: Integration tests, E2E tests, Architecture tests (tested separately below)
          #
          # RATIONALE FOR INFRASTRUCTURE EXCLUSION:
          # Infrastructure tests are excluded from module-based coverage runs (--filter) because:
          # 1. Infrastructure tests often require real dependencies (databases, message brokers, etc.)
          # 2. Mixing unit tests (mocked) with infrastructure tests distorts coverage metrics
          # 3. Infrastructure/Integration tests run separately (lines 345-366) with proper test environment
          # 4. This separation ensures unit test coverage accurately reflects business logic coverage
          #
          # FORMAT: "ModuleName:path/to/module/tests/:IncludeFilter"
          MODULES=(
            # Domain module tests
            "Users:src/Modules/Users/Tests/:MeAjudaAi.Modules.Users.*"
            "Providers:src/Modules/Providers/Tests/:MeAjudaAi.Modules.Providers.*"
            "Documents:src/Modules/Documents/Tests/:MeAjudaAi.Modules.Documents.*"
            "ServiceCatalogs:src/Modules/ServiceCatalogs/Tests/:MeAjudaAi.Modules.ServiceCatalogs.*"
            "Locations:src/Modules/Locations/Tests/:MeAjudaAi.Modules.Locations.*"
            "SearchProviders:src/Modules/SearchProviders/Tests/:MeAjudaAi.Modules.SearchProviders.*"

            # System/Shared tests (626+ tests - HIGH PRIORITY)
            "Shared:tests/MeAjudaAi.Shared.Tests/:MeAjudaAi.Shared"
            "ApiService:tests/MeAjudaAi.ApiService.Tests/:MeAjudaAi.ApiService"
          )

          # Source shared utility functions once before module loop
          RUNSETTINGS_SCRIPT="./.github/scripts/generate-runsettings.sh"
          if [ ! -f "$RUNSETTINGS_SCRIPT" ] || [ ! -r "$RUNSETTINGS_SCRIPT" ]; then
            echo "‚ùå ERROR: Required script not found or not readable: $RUNSETTINGS_SCRIPT"
            exit 1
          fi
          if ! source "$RUNSETTINGS_SCRIPT"; then
            echo "‚ùå ERROR: Failed to source $RUNSETTINGS_SCRIPT (exit code: $?)"
            exit 1
          fi

          # Run unit tests for each module with coverage
          for module_info in "${MODULES[@]}"; do
            IFS=':' read -r module_name module_path include_pattern <<< "$module_info"

            if [ -d "$module_path" ]; then
              echo "================================"
              echo "üß™ UNIT TESTS - $module_name (WITH COVERAGE)"
              echo "================================"

              # Create specific output directory for this module
              MODULE_COVERAGE_DIR="./coverage/${module_name,,}"
              mkdir -p "$MODULE_COVERAGE_DIR"

            # CRITICAL: Include ALL assemblies matching the pattern to get full coverage
            # The Include filter determines which assemblies are instrumented for coverage
            # Using broad patterns ensures we capture all source code
            if [ -n "$include_pattern" ]; then
              INCLUDE_FILTER="[${include_pattern}]*"
            else
              # Default to all MeAjudaAi assemblies if no specific pattern
              INCLUDE_FILTER="[MeAjudaAi*]*"
            fi

            # Validate filter is not empty or trivial
            if [ "$INCLUDE_FILTER" = "[]*" ] || [ "$INCLUDE_FILTER" = "[].*" ]; then
              echo "‚ö†Ô∏è  INCLUDE_FILTER is trivial, falling back to [MeAjudaAi*]*"
              INCLUDE_FILTER="[MeAjudaAi*]*"
            fi

            # NOTE: EXCLUDE_FILTER excludes test assemblies, migrations, and compiler-generated code
            # This ensures coverage metrics reflect only hand-written production code
            # Excluded patterns:
            #   - Test assemblies: [*.Tests*]*, [*Test*]*, [testhost]*
            #   - Migrations: [*]*Migrations* (any class/namespace containing "Migrations")
            #   - Database: [*]*.Database (database-related generated code)
            #   - Contracts: [*]*.Contracts (DTOs, no logic to test)
            #   - DbContextFactory: [*]*DbContextFactory* (EF Core design-time factories)
            #   - Program: [*]*.Program (application entry points)
            #   - OpenApi generated: [*Microsoft.AspNetCore.OpenApi.Generated*]*
            #   - Compiler services: [*System.Runtime.CompilerServices*]*
            #   - Regex generator: [*System.Text.RegularExpressions.Generated*]*
            EXCLUDE_FILTER="[*.Tests*]*,[*Test*]*,[testhost]*,[*]*Migrations*,[*]*.Database,[*]*.Contracts,[*]*DbContextFactory*,[*]*.Program,[*Microsoft.AspNetCore.OpenApi.Generated*]*,[*System.Runtime.CompilerServices*]*,[*System.Text.RegularExpressions.Generated*]*"
            EXCLUDE_BY_FILE="**/*OpenApi*.generated.cs,**/System.Runtime.CompilerServices*.cs,**/*RegexGenerator.g.cs,**/Migrations/*.cs,**/Migrations/**/*.cs,**/Database/*.cs,**/*DbContextFactory.cs,**/Program.cs"

            echo "  Include: $INCLUDE_FILTER"
            echo "  Exclude: $EXCLUDE_FILTER"
            echo "  ExcludeByFile: $EXCLUDE_BY_FILE"

            # Create temporary runsettings file for this module with proper XML escaping
            RUNSETTINGS_FILE="/tmp/${module_name,,}.runsettings"
            EXCLUDE_BY_ATTRIBUTE="Obsolete,GeneratedCode,CompilerGenerated"
            generate_runsettings \
              "$RUNSETTINGS_FILE" \
              "$EXCLUDE_FILTER" \
              "$EXCLUDE_BY_FILE" \
              "$EXCLUDE_BY_ATTRIBUTE" \
              "$INCLUDE_FILTER"


            # NOTE: We run ALL tests (no --filter) because:
            # 1. Tests should exercise all code paths
            # 2. Include/Exclude filters in .runsettings control COVERAGE (what code is instrumented)
            # 3. Test filters only control which TESTS run, not what CODE is covered
            dotnet test "$module_path" \
                --configuration Release \
                --verbosity normal \
                --collect:"XPlat Code Coverage" \
                --results-directory "$MODULE_COVERAGE_DIR" \
                --logger "trx;LogFileName=${module_name,,}-test-results.trx" \
                --settings "/tmp/${module_name,,}.runsettings"

              TEST_EXIT_CODE=$?
              if [ $TEST_EXIT_CODE -ne 0 ]; then
                echo "‚ùå Tests failed for $module_name with exit code $TEST_EXIT_CODE"
                exit $TEST_EXIT_CODE
              fi

              # Find and rename the coverage file to a predictable name
              if [ -d "$MODULE_COVERAGE_DIR" ]; then
                echo "üîç Searching for coverage files in $MODULE_COVERAGE_DIR..."
                echo "üìÇ Directory contents:"
                find "$MODULE_COVERAGE_DIR" -type f -name "*.xml" | head -10

                # Look for both opencover and cobertura formats (search recursively in GUID subdirs)
                COVERAGE_FILE=$(find "$MODULE_COVERAGE_DIR" -type f \
                  \( -name "coverage.opencover.xml" -o -name "coverage.cobertura.xml" \) \
                  -print -quit)
                if [ -f "$COVERAGE_FILE" ]; then
                  echo "‚úÖ Found coverage file: $COVERAGE_FILE"
                  # Copy to standardized name based on original format
                  if [[ "$COVERAGE_FILE" == *"cobertura"* ]]; then
                    cp "$COVERAGE_FILE" "$MODULE_COVERAGE_DIR/${module_name,,}.cobertura.xml"
                  else
                    cp "$COVERAGE_FILE" "$MODULE_COVERAGE_DIR/${module_name,,}.opencover.xml"
                  fi
                else
                  echo "‚ö†Ô∏è  Coverage file not found for $module_name"
                  echo "üìã Available XML files:"
                  find "$MODULE_COVERAGE_DIR" -name "*.xml" -type f | head -5
                fi
              else
                echo "‚ùå Coverage directory not found: $MODULE_COVERAGE_DIR"
              fi
            else
              echo "‚ö†Ô∏è  $module_name tests not found at $module_path - skipping"
            fi
          done

          echo ""
          echo "üìä COVERAGE FILES SUMMARY"
          echo "========================="
          echo "Total coverage XML files generated:"
          find ./coverage -type f \( -name "*.opencover.xml" -o -name "*.cobertura.xml" \) | wc -l
          echo ""
          echo "Coverage files by module:"
          find ./coverage -type f \( -name "*.opencover.xml" -o -name "*.cobertura.xml" \) -printf "%f\n" | sort | head -20
          echo ""
          
          echo "üîç DEBUG: Verifying coverage files for CodeCoverageSummary..."
          for module in users providers documents servicecatalogs locations searchproviders shared apiservice; do
            if [ -f "coverage/${module}/${module}.opencover.xml" ]; then
              echo "  ‚úÖ coverage/${module}/${module}.opencover.xml exists"
              # Show file size and first sequenceCoverage value as sanity check
              FILE_SIZE=$(stat -c%s "coverage/${module}/${module}.opencover.xml" 2>/dev/null || echo "unknown")
              COVERAGE=$(grep -o 'sequenceCoverage="[^"]*"' "coverage/${module}/${module}.opencover.xml" 2>/dev/null | head -1 | cut -d'"' -f2 || echo "N/A")
              echo "     Size: ${FILE_SIZE} bytes, Coverage: ${COVERAGE}%"
            else
              echo "  ‚ùå coverage/${module}/${module}.opencover.xml NOT FOUND"
            fi
          done
          echo ""

      - name: Run Architecture Tests
        if: always()
        run: |
          echo "üß™ Running Architecture tests (no database required)..."

          # Only run Architecture tests in PR validation (fast, no database dependency)
          if [ -d "tests/MeAjudaAi.Architecture.Tests/" ]; then
            echo "================================"
            echo "üìê ARCHITECTURE TESTS"
            echo "================================"
            dotnet test "tests/MeAjudaAi.Architecture.Tests/" \
              --configuration Release \
              --no-build \
              --verbosity normal \
              --logger "trx;LogFileName=architecture-test-results.trx"
            
            TEST_EXIT_CODE=$?
            if [ $TEST_EXIT_CODE -ne 0 ]; then
              echo "‚ùå Architecture tests failed with exit code $TEST_EXIT_CODE"
              exit $TEST_EXIT_CODE
            fi
          else
            echo "‚ö†Ô∏è  Architecture tests not found - skipping"
          fi

      - name: Run Integration Tests
        env:
          ASPNETCORE_ENVIRONMENT: Testing
          INTEGRATION_TESTS: true
          ConnectionStrings__DefaultConnection: ${{ steps.db.outputs.connection-string }}
          ConnectionStrings__Users: ${{ steps.db.outputs.connection-string }}
          ConnectionStrings__Search: ${{ steps.db.outputs.connection-string }}
          ConnectionStrings__meajudaai-db: ${{ steps.db.outputs.connection-string }}
        run: |
          echo "üîó Running Integration tests..."

          # Source shared utility functions with existence check
          RUNSETTINGS_SCRIPT="./.github/scripts/generate-runsettings.sh"
          if [ ! -f "$RUNSETTINGS_SCRIPT" ] || [ ! -r "$RUNSETTINGS_SCRIPT" ]; then
            echo "‚ùå ERROR: Required script not found or not readable: $RUNSETTINGS_SCRIPT"
            exit 1
          fi
          if ! source "$RUNSETTINGS_SCRIPT"; then
            echo "‚ùå ERROR: Failed to source $RUNSETTINGS_SCRIPT (exit code: $?)"
            exit 1
          fi

          if [ -d "tests/MeAjudaAi.Integration.Tests/" ]; then
            echo "================================"
            echo "üîó INTEGRATION TESTS"
            echo "================================"
            
            # Create runsettings with same exclusions as unit tests
            INTEGRATION_RUNSETTINGS="/tmp/integration.runsettings"
            # Exclude compiler-generated files AND test assembly files from coverage
            EXCLUDE_BY_FILE="**/*OpenApi*.generated.cs,**/System.Runtime.CompilerServices*.cs,**/*RegexGenerator.g.cs"
            EXCLUDE_BY_ATTRIBUTE="Obsolete,GeneratedCode,CompilerGenerated"
            EXCLUDE_FILTER="[*.Tests]*,[*.Tests.*]*,[*Test*]*,[testhost]*"
            INCLUDE_FILTER="[MeAjudaAi*]*"  # Instrument all MeAjudaAi assemblies
            
            generate_runsettings \
              "$INTEGRATION_RUNSETTINGS" \
              "$EXCLUDE_FILTER" \
              "$EXCLUDE_BY_FILE" \
              "$EXCLUDE_BY_ATTRIBUTE" \
              "$INCLUDE_FILTER"
            
            dotnet test "tests/MeAjudaAi.Integration.Tests/" \
              --configuration Release \
              --no-build \
              --verbosity normal \
              --logger "trx;LogFileName=integration-test-results.trx" \
              --collect:"XPlat Code Coverage" \
              --results-directory ./coverage/integration \
              --settings "$INTEGRATION_RUNSETTINGS"
            
            TEST_EXIT_CODE=$?
            if [ $TEST_EXIT_CODE -ne 0 ]; then
              echo "‚ùå Integration tests failed with exit code $TEST_EXIT_CODE"
              exit $TEST_EXIT_CODE
            fi
          else
            echo "‚ö†Ô∏è  Integration tests not found - skipping"
          fi

      - name: Run E2E Tests
        env:
          ASPNETCORE_ENVIRONMENT: Testing
          INTEGRATION_TESTS: true
          ConnectionStrings__DefaultConnection: ${{ steps.db.outputs.connection-string }}
          ConnectionStrings__Users: ${{ steps.db.outputs.connection-string }}
          ConnectionStrings__Search: ${{ steps.db.outputs.connection-string }}
          ConnectionStrings__meajudaai-db: ${{ steps.db.outputs.connection-string }}
        run: |
          echo "üåê Running E2E tests..."

          # Source shared utility functions with existence check
          RUNSETTINGS_SCRIPT="./.github/scripts/generate-runsettings.sh"
          if [ ! -f "$RUNSETTINGS_SCRIPT" ] || [ ! -r "$RUNSETTINGS_SCRIPT" ]; then
            echo "‚ùå ERROR: Required script not found or not readable: $RUNSETTINGS_SCRIPT"
            exit 1
          fi
          if ! source "$RUNSETTINGS_SCRIPT"; then
            echo "‚ùå ERROR: Failed to source $RUNSETTINGS_SCRIPT (exit code: $?)"
            exit 1
          fi

          if [ -d "tests/MeAjudaAi.E2E.Tests/" ]; then
            echo "================================"
            echo "üåê E2E TESTS"
            echo "================================"
            
            # Create runsettings with same exclusions as unit tests
            E2E_RUNSETTINGS="/tmp/e2e.runsettings"
            # Exclude compiler-generated files AND test assembly files from coverage
            EXCLUDE_BY_FILE="**/*OpenApi*.generated.cs,**/System.Runtime.CompilerServices*.cs,**/*RegexGenerator.g.cs"
            EXCLUDE_BY_ATTRIBUTE="Obsolete,GeneratedCode,CompilerGenerated"
            EXCLUDE_FILTER="[*.Tests]*,[*.Tests.*]*,[*Test*]*,[testhost]*"
            INCLUDE_FILTER="[MeAjudaAi*]*"  # Instrument all MeAjudaAi assemblies
            
            generate_runsettings \
              "$E2E_RUNSETTINGS" \
              "$EXCLUDE_FILTER" \
              "$EXCLUDE_BY_FILE" \
              "$EXCLUDE_BY_ATTRIBUTE" \
              "$INCLUDE_FILTER"
            
            dotnet test "tests/MeAjudaAi.E2E.Tests/" \
              --configuration Release \
              --no-build \
              --verbosity normal \
              --logger "trx;LogFileName=e2e-test-results.trx" \
              --collect:"XPlat Code Coverage" \
              --results-directory ./coverage/e2e \
              --settings "$E2E_RUNSETTINGS"
            
            TEST_EXIT_CODE=$?
            if [ $TEST_EXIT_CODE -ne 0 ]; then
              echo "‚ùå E2E tests failed with exit code $TEST_EXIT_CODE"
              exit $TEST_EXIT_CODE
            fi
          else
            echo "‚ö†Ô∏è  E2E tests not found - skipping"
          fi

          echo ""
          echo "‚úÖ All test categories completed"

      - name: Generate Aggregated Coverage Report
        if: always()
        run: |
          echo "üìä Generating aggregated coverage report from ALL tests..."
          
          # Install ReportGenerator
          dotnet tool install --global dotnet-reportgenerator-globaltool || dotnet tool update --global dotnet-reportgenerator-globaltool
          
          # Add dotnet tools to PATH
          export PATH="$PATH:$HOME/.dotnet/tools"
          
          # Pre-flight check: verify all expected coverage files exist
          echo "üîç Pre-flight check: Verifying coverage files..."
          MISSING_FILES=0
          for module in users providers documents servicecatalogs locations searchproviders shared apiservice; do
            if ! find "coverage/${module}" -name "*.opencover.xml" -type f | grep -q .; then
              echo "  ‚ö†Ô∏è  Warning: No .opencover.xml files found for ${module}"
              MISSING_FILES=$((MISSING_FILES + 1))
            else
              echo "  ‚úÖ Found coverage file(s) for ${module}"
            fi
          done
          
          # Check for Integration/E2E coverage
          if find "coverage/integration" -name "*.xml" -type f | grep -q .; then
            echo "  ‚úÖ Found Integration test coverage"
          fi
          if find "coverage/e2e" -name "*.xml" -type f | grep -q .; then
            echo "  ‚úÖ Found E2E test coverage"
          fi
          
          if [ $MISSING_FILES -gt 0 ]; then
            echo "‚ö†Ô∏è  Warning: $MISSING_FILES module(s) missing coverage files"
            echo "   ReportGenerator will combine only available modules"
          fi
          
          # Generate aggregated Cobertura XML combining Unit + Integration + E2E coverage
          # Note: OpenCover output format requires Pro license, but Cobertura is free
          # We read OpenCover input files and generate Cobertura output
          echo "üîó Combining coverage from Unit + Integration + E2E tests..."
          
          # ReportGenerator filter syntax: semicolon-separated, +/- prefix, no brackets
          # Include main assemblies (use wildcards for all module components)
          INCLUDE_FILTER="+MeAjudaAi.Modules.Users.*;+MeAjudaAi.Modules.Providers.*;+MeAjudaAi.Modules.Documents.*;+MeAjudaAi.Modules.ServiceCatalogs.*;+MeAjudaAi.Modules.Locations.*;+MeAjudaAi.Modules.SearchProviders.*;+MeAjudaAi.Shared*;+MeAjudaAi.ApiService*"
          # CRITICAL: Exclude .Tests assemblies, Migrations, infrastructure classes, Program.cs, DbContextFactory
          EXCLUDE_FILTER="-*.Tests;-*.Tests.*;-*Test*;-testhost;-xunit*;-*.Migrations.*;-*.Contracts;-*.Database;-*DbContextFactory;-*.Program;-*.Keycloak.*;-*.Monitoring.*;-*NoOp*;-*RabbitMq*;-*ServiceBus*;-*Hangfire*;-*.Jobs.*;-*Options;-*BaseDesignTimeDbContextFactory*;-*SchemaPermissionsManager;-*SimpleHostEnvironment;-*CacheWarmupService;-*GeoPointConverter;-*ModuleNames;-*ModuleApiInfo;-*MessagingExtensions;-*ICacheableQuery"
          
          reportgenerator \
            -reports:"coverage/users/*.opencover.xml;coverage/providers/*.opencover.xml;coverage/documents/*.opencover.xml;coverage/servicecatalogs/*.opencover.xml;coverage/locations/*.opencover.xml;coverage/searchproviders/*.opencover.xml;coverage/shared/*.opencover.xml;coverage/apiservice/*.opencover.xml;coverage/integration/**/*.xml;coverage/e2e/**/*.xml" \
            -targetdir:"coverage/aggregate" \
            -reporttypes:"Cobertura" \
            -assemblyfilters:"$INCLUDE_FILTER" \
            -classfilters:"$EXCLUDE_FILTER" \
            -filefilters:"-*Migrations*"
          
          if [ -f "coverage/aggregate/Cobertura.xml" ]; then
            echo "‚úÖ Aggregated coverage report generated: coverage/aggregate/Cobertura.xml"
            # Show summary stats from Cobertura XML
            COVERAGE=$(grep -o 'line-rate="[^"]*"' coverage/aggregate/Cobertura.xml | head -1 | cut -d'"' -f2 | awk '{printf "%.2f", $1 * 100}' || echo "N/A")
            echo "üìà Combined Line Coverage (Unit + Integration + E2E): ${COVERAGE}%"
          else
            echo "‚ùå Failed to generate aggregated coverage report"
          fi

      - name: Validate namespace reorganization
        run: |
          echo "üîç Validating namespace reorganization..."
          if grep -R -nE '^[[:space:]]*using[[:space:]]+MeAjudaAi\.Shared\.Common;' -- src/ \
              2>/dev/null; then
            echo "‚ùå Found old namespace imports"
            exit 1
          else
            echo "‚úÖ Conformidade com namespaces validada"
          fi

      - name: Upload coverage reports
        uses: actions/upload-artifact@v5
        if: always()
        with:
          name: coverage-reports
          path: coverage/**
          retention-days: 7
          compression-level: 6
          if-no-files-found: ignore

      - name: Upload Test Results
        uses: actions/upload-artifact@v5
        if: always()
        with:
          name: test-results
          path: "**/*.trx"
          retention-days: 7
          compression-level: 6
          if-no-files-found: ignore

      - name: List Coverage Files (Debug)
        run: |
          echo "üîç Listing coverage files for debugging..."
          echo "Coverage directory structure:"
          find ./coverage -type f 2>/dev/null | head -20 || echo "No files found in coverage directory"
          echo ""
          echo "OpenCover XML files:"
          find ./coverage -name "*.opencover.xml" -type f 2>/dev/null || echo "No .opencover.xml files found"
          echo ""
          echo "Any XML files:"
          find ./coverage -name "*.xml" -type f 2>/dev/null || echo "No XML files found"
          echo ""
          echo "Coverage directory contents:"
          ls -la ./coverage/ 2>/dev/null || echo "Coverage directory not found"
          echo ""
          echo "Checking for coverage.xml files:"
          find ./coverage -name "coverage.xml" -type f 2>/dev/null || echo "No coverage.xml files found"

      - name: Fix Coverage Files (if needed)
        run: |
          echo "üîß Attempting to fix coverage file locations and names..."

          # Find any coverage.xml files and rename them to appropriate format
          find ./coverage -name "coverage.xml" -type f | while read -r file; do
            dir=$(dirname "$file")
            module=$(basename "$dir")
            new_file="$dir/$module.cobertura.xml"
            echo "Copying $file to $new_file"
            cp "$file" "$new_file"
          done

          # Find coverage files in nested directories and copy to module directories
          find ./coverage -type f \
            \( -name "coverage.opencover.xml" -o -name "coverage.cobertura.xml" \) \
            | while read -r file; do
            # Get the module directory (should be like ./coverage/users/)
            module_dir=$(echo "$file" | sed 's|coverage/\([^/]*\)/.*|coverage/\1|')
            module_name=$(basename "$module_dir")

            # Determine target file based on source format
            if [[ "$file" == *"cobertura"* ]]; then
              target_file="$module_dir/$module_name.cobertura.xml"
            else
              target_file="$module_dir/$module_name.opencover.xml"
            fi

            if [ "$file" != "$target_file" ]; then
              echo "Copying $file to $target_file"
              cp "$file" "$target_file" 2>/dev/null || true
            fi
          done

          echo "Coverage files after processing:"
          find ./coverage -name "*.xml" -type f 2>/dev/null || echo "No XML coverage files found"

      - name: Code Coverage Summary
        id: coverage_cobertura_aggregate
        continue-on-error: true
        uses: irongut/CodeCoverageSummary@v1.3.0
        with:
          filename: 'coverage/aggregate/Cobertura.xml'
          badge: true
          fail_below_min: false
          format: markdown
          hide_branch_rate: false
          hide_complexity: false
          indicators: true
          output: both
          thresholds: '70 85'

      - name: Alternative Coverage Summary (Individual modules - OpenCover)
        id: coverage_opencover_individual
        if: ${{ always() && steps.coverage_cobertura_aggregate.outcome != 'success' }}
        uses: irongut/CodeCoverageSummary@v1.3.0
        with:
          filename: 'coverage/users/*.opencover.xml,coverage/providers/*.opencover.xml,coverage/documents/*.opencover.xml,coverage/servicecatalogs/*.opencover.xml,coverage/locations/*.opencover.xml,coverage/searchproviders/*.opencover.xml,coverage/shared/*.opencover.xml,coverage/apiservice/*.opencover.xml'
          badge: true
          fail_below_min: false
          format: markdown
          hide_branch_rate: false
          hide_complexity: false
          indicators: true
          output: both
          thresholds: '80 90'
        continue-on-error: true

      - name: Alternative Coverage Summary (Cobertura format)
        id: coverage_cobertura
        if: ${{ always() && steps.coverage_cobertura_aggregate.outcome != 'success' && steps.coverage_opencover_individual.outcome != 'success' }}
        uses: irongut/CodeCoverageSummary@v1.3.0
        with:
          filename: 'coverage/users/*.cobertura.xml,coverage/providers/*.cobertura.xml,coverage/documents/*.cobertura.xml,coverage/servicecatalogs/*.cobertura.xml,coverage/locations/*.cobertura.xml,coverage/searchproviders/*.cobertura.xml,coverage/shared/*.cobertura.xml,coverage/apiservice/*.cobertura.xml'
          badge: true
          fail_below_min: false
          format: markdown
          hide_branch_rate: false
          hide_complexity: false
          indicators: true
          output: both
          thresholds: '80 90'
        continue-on-error: true

      - name: Fallback Coverage Summary (any XML)
        id: coverage_fallback
        if: >-
          ${{ always() &&
              steps.coverage_cobertura_aggregate.outcome != 'success' &&
              steps.coverage_opencover_individual.outcome != 'success' &&
              steps.coverage_cobertura.outcome != 'success' }}
        uses: irongut/CodeCoverageSummary@v1.3.0
        with:
          filename: 'coverage/**/*.xml'
          badge: true
          fail_below_min: false
          format: markdown
          hide_branch_rate: false
          hide_complexity: false
          indicators: true
          output: both
          thresholds: '80 90'
        continue-on-error: true

      - name: Display Coverage Percentages
        if: always()
        run: |
          echo "üìä CODE COVERAGE SUMMARY"
          echo "========================"
          echo ""
          
          # Only analyze coverage from the 8 main modules (exclude Integration/E2E tests)
          MODULES=("users" "providers" "documents" "servicecatalogs" "locations" "searchproviders" "shared" "apiservice")
          
          for module in "${MODULES[@]}"; do
            coverage_file="./coverage/${module}/${module}.opencover.xml"
            if [ -f "$coverage_file" ]; then
              echo "üìÑ Module: ${module^}"
              # Extract coverage statistics from OpenCover XML
              if command -v awk >/dev/null 2>&1; then
                COVERAGE_LINE_ATTR='sequenceCoverage="[^"]*"'
                COVERAGE_BRANCH_ATTR='branchCoverage="[^"]*"'
                lines_covered=$(grep -o "$COVERAGE_LINE_ATTR" "$coverage_file" 2>/dev/null | \
                  head -1 | grep -o '[0-9.]*' || echo "N/A")
                branch_covered=$(grep -o "$COVERAGE_BRANCH_ATTR" "$coverage_file" 2>/dev/null | \
                  head -1 | grep -o '[0-9.]*' || echo "N/A")
                if [ "$lines_covered" != "N/A" ]; then
                  echo "  üìà Line Coverage: ${lines_covered}%"
                fi
                if [ "$branch_covered" != "N/A" ]; then
                  echo "  üåø Branch Coverage: ${branch_covered}%"
                fi
              fi
              echo ""
            fi
          done

          echo "üí° For detailed coverage report, check the 'Code Coverage Summary' step above"
          echo "üéØ Minimum thresholds: 80% (warning) / 90% (good)"

      - name: Select Coverage Outputs
        id: select_coverage_outputs
        if: always()
        run: |
          echo "üîç Detecting coverage files..."

          if [ -f "coverage/aggregate/Cobertura.xml" ]; then
            COVERAGE_FILE="coverage/aggregate/Cobertura.xml"
            SOURCE="Cobertura (Aggregated Direct)"
            echo "‚úÖ Found aggregated Cobertura file: $COVERAGE_FILE"
          elif find coverage -name "*.opencover.xml" -type f | head -1 >/dev/null 2>&1; then
            COVERAGE_FILE=$(find coverage -name "*.opencover.xml" -type f | head -1)
            SOURCE="OpenCover (Direct)"
            echo "Found OpenCover file: $COVERAGE_FILE"
          elif find coverage -name "*.cobertura.xml" -type f | head -1 >/dev/null 2>&1; then
            COVERAGE_FILE=$(find coverage -name "*.cobertura.xml" -type f | head -1)
            SOURCE="Cobertura (Direct)"
            echo "Found Cobertura file: $COVERAGE_FILE"
          elif find coverage -name "*.xml" -type f | head -1 >/dev/null 2>&1; then
            COVERAGE_FILE=$(find coverage -name "*.xml" -type f | head -1)
            SOURCE="XML (Direct)"
            echo "Found XML file: $COVERAGE_FILE"
          else
            COVERAGE_FILE=""
            SOURCE="None"
            echo "No coverage files found"
          fi

          if [ -n "$COVERAGE_FILE" ]; then
            # Try to extract basic coverage percentage from XML
            if command -v grep >/dev/null 2>&1; then
              # Look for line-rate or sequenceCoverage attributes
              LINE_RATE=$(grep -o 'line-rate="[^"]*"' "$COVERAGE_FILE" 2>/dev/null | head -1 | cut -d'"' -f2)
              if [ -z "$LINE_RATE" ]; then
                LINE_RATE=$(grep -o 'sequenceCoverage="[^"]*"' "$COVERAGE_FILE" 2>/dev/null | head -1 | cut -d'"' -f2)
              fi

              if [ -n "$LINE_RATE" ]; then
                # Convert decimal to percentage if needed (auto-detect format)
                # If value <= 1.0, assume decimal (0.75 -> 75.00), else assume already percentage (75.5 -> 75.50)
                PERCENTAGE=$(echo "$LINE_RATE" | awk '{if ($1 <= 1.0) printf "%.2f", $1 * 100; else printf "%.2f", $1}')
                SUMMARY="**Coverage**: ${PERCENTAGE}% (extracted from $SOURCE)"
                BADGE="![Coverage](https://img.shields.io/badge/coverage-${PERCENTAGE}%25-brightgreen)"
              else
                SUMMARY="**Coverage**: Available (file found, percentage not extracted)"
                BADGE="![Coverage](https://img.shields.io/badge/coverage-available-blue)"
              fi
            else
              SUMMARY="**Coverage**: Files found but could not extract percentage"
              BADGE="![Coverage](https://img.shields.io/badge/coverage-found-blue)"
            fi
          else
            SUMMARY="Coverage data not available"
            BADGE=""
          fi

          # Export outputs
          echo "source=$SOURCE" >> $GITHUB_OUTPUT
          echo "badge=$BADGE" >> $GITHUB_OUTPUT
          echo "summary=$SUMMARY" >> $GITHUB_OUTPUT

          # Export multiline summary using heredoc
          {
            echo 'summary<<EOF'
            echo "$SUMMARY"
            echo 'EOF'
          } >> $GITHUB_OUTPUT

          echo "Coverage source: $SOURCE"
          echo "Summary: $SUMMARY"

      - name: Add Coverage PR Comment
        uses: marocchino/sticky-pull-request-comment@v2
        if: github.event_name == 'pull_request'
        with:
          recreate: true
          header: coverage-report
          message: |
            ## üìä Code Coverage Report

            ${{ steps.select_coverage_outputs.outputs.summary }}

            ### üìà Coverage Details
            - **Coverage badges**: ${{ steps.select_coverage_outputs.outputs.badge }}
            - **Minimum threshold**: 80% (warning) / 90% (good)
            - **Report format**: Auto-detected from OpenCover/Cobertura XML files
            - **Coverage source**: ${{ steps.select_coverage_outputs.outputs.source }}

            ### üìã Coverage Analysis
            - **Line Coverage**: Shows percentage of code lines executed during tests
            - **Branch Coverage**: Shows percentage of code branches/conditions tested
            - **Complexity**: Code complexity metrics for maintainability

            ### üéØ Quality Gates
            - ‚úÖ **Pass**: Coverage ‚â• 90%
            - ‚ö†Ô∏è **Warning**: Coverage 80-89%
            - ‚ùå **Fail**: Coverage < 80%

            ### üìÅ Artifacts
            - **Coverage reports**: Available in workflow artifacts
            - **Test results**: TRX files with detailed test execution data

            *This comment is updated automatically on each push to track coverage trends.*

      # Refactored: Extracted to reusable action for better maintainability
      # See: .github/actions/validate-coverage/README.md for documentation
      - name: Validate Coverage Thresholds
        if: always()
        uses: ./.github/actions/validate-coverage
        with:
          coverage-directory: './coverage'
          threshold: '90'
          strict-mode: ${{ env.STRICT_COVERAGE }}
          opencover-outcome: ${{ steps.coverage_opencover_individual.outcome }}
          cobertura-outcome: ${{ steps.coverage_cobertura.outcome }}
          fallback-outcome: ${{ steps.coverage_fallback.outcome }}

  # Job 2: Security Scan (Consolidated)
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Setup .NET
        uses: actions/setup-dotnet@v5
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Restore dependencies
        run: dotnet restore MeAjudaAi.sln

      - name: Run Security Audit
        run: dotnet list package --vulnerable --include-transitive

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: OSV-Scanner (fail on HIGH/CRITICAL)
        run: |
          echo "üîç Installing OSV-Scanner..."
          # Install OSV-Scanner with pinned version for reproducibility
          OSV_VERSION="v1.8.3"
          OSV_URL="https://github.com/google/osv-scanner/releases/download/${OSV_VERSION}"

          # Retry logic for network transient failures
          max_retries=3
          retry_count=0

          while [ $retry_count -lt $max_retries ]; do
            if curl -sSfL --connect-timeout 10 --max-time 30 \
                "${OSV_URL}/osv-scanner_linux_amd64" -o osv-scanner; then
              echo "‚úÖ Download successful"
              chmod +x osv-scanner
              break
            else
              retry_count=$((retry_count + 1))
              if [ $retry_count -lt $max_retries ]; then
                echo "‚ö†Ô∏è  Download failed (attempt $retry_count/$max_retries), retrying in 5s..."
                sleep 5
              else
                echo "‚ùå Download failed after $max_retries attempts"
                echo "üí° Trying fallback: install via Go toolchain..."

                # Fallback: Install via Go if available
                if command -v go >/dev/null 2>&1; then
                  echo "‚ÑπÔ∏è  Using Go to install OSV-Scanner..."
                  go install github.com/google/osv-scanner/cmd/osv-scanner@${OSV_VERSION}
                  # Copy to local dir for consistent usage
                  cp "$(go env GOPATH)/bin/osv-scanner" ./osv-scanner 2>/dev/null || \
                    ln -s "$(go env GOPATH)/bin/osv-scanner" ./osv-scanner
                else
                  echo "‚ùå Go toolchain not available, cannot install OSV-Scanner"
                  echo "‚ö†Ô∏è  CRITICAL: Vulnerability scan cannot be performed"
                  echo "üí° MITIGATION: Ensure runner has Go ‚â•1.18 installed or provide pre-built OSV-Scanner binary"
                  echo "üí° SECURITY NOTE: This workflow MUST fail when vulnerability scanning is unavailable."
                  echo "   To fix: ensure Go is installed on the runner or configure a pre-built OSV-Scanner binary."
                  exit 1  # Fail the workflow - security scanning is mandatory
                fi
              fi
            fi
          done

          echo "OSV-Scanner version and help:"
          ./osv-scanner --version || echo "Version command failed"
          ./osv-scanner scan --help | head -20 || echo "Help command failed"

          echo "üîç Running vulnerability scan..."
          # Run OSV-Scanner and capture exit code
          osv_exit_code=0
          ./osv-scanner scan --recursive --skip-git . || osv_exit_code=$?

          if [ $osv_exit_code -eq 0 ]; then
            echo "‚úÖ No vulnerabilities found"
          else
            echo "‚ö†Ô∏è OSV-Scanner found vulnerabilities (exit code: $osv_exit_code)"
            echo "üìÑ Running detailed scan for analysis..."

            # Run again with JSON output for detailed analysis
            ./osv-scanner scan --recursive --skip-git --format json . > osv-results.json || true

            if [ -f osv-results.json ]; then
              # Count HIGH/CRITICAL by CVSS (>=7.0) with safe parsing and textual severity mapping
              HIGH_OR_CRIT=$(
                jq -r '
                  # Function to safely convert severity scores to numbers
                  def safe_score_to_number:
                    if type == "number" then .
                    elif type == "string" then
                      (tonumber? // (
                        (. | ascii_upcase) as $upper
                        | if $upper == "CRITICAL" then 9
                          elif $upper == "HIGH" then 7
                          elif $upper == "MEDIUM" then 5
                          elif $upper == "LOW" then 3
                          else 0
                          end
                      ))
                    else 0
                    end;

                  [.results[]?.packages[]?.vulnerabilities[]?
                    | ( [(.severity // [])[]?.score? | safe_score_to_number] | max // 0 )
                    | select(. >= 7.0)
                  ] | length
                ' osv-results.json 2>/dev/null
              )

              if [ "${HIGH_OR_CRIT:-0}" -gt 0 ]; then
                echo "‚ùå Found $HIGH_OR_CRIT HIGH/CRITICAL vulnerabilities"
                echo "üìã First 10 vulnerabilities found:"
                # Use inline jq program to display vulnerability summary
                jq -r '.results[]?.packages[]?.vulnerabilities[]? |
                  "- \(.id): \(.summary // "No summary")"' \
                  osv-results.json 2>/dev/null | head -10
                echo ""
                echo "üö´ Security scan failed - vulnerabilities detected"
                echo "üí° Please review and fix vulnerabilities before merging"

                # Fail the workflow
                exit 1
              else
                echo "‚úÖ No HIGH/CRITICAL vulnerabilities found"
                # Count total vulnerabilities for info
                TOTAL_VULNS=$(jq -r '.results[]?.packages[]?.vulnerabilities[]? | .id' \
                  osv-results.json 2>/dev/null | wc -l)
                if [ "$TOTAL_VULNS" -gt 0 ]; then
                  echo "‚ÑπÔ∏è  Found $TOTAL_VULNS low/medium severity vulnerabilities (ignored)"
                fi
              fi
            else
              echo "‚ùå OSV-Scanner failed but no results file generated"
              exit 1
            fi
          fi

      - name: Secret Detection with TruffleHog
        if: ${{ github.event_name == 'pull_request' }}
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: ${{ github.event.pull_request.base.ref }}
          head: ${{ github.event.pull_request.head.sha }}
          extra_args: --debug --only-verified
  # Job 3: Markdown Link Validation (Simplified)
  markdown-link-check:
    name: Validate Markdown Links
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Cache lychee results
        uses: actions/cache@v5
        with:
          path: .lycheecache
          key: lychee-${{ runner.os }}-${{ hashFiles('**/*.md','config/lychee.toml') }}
          restore-keys: |
            lychee-${{ runner.os }}-

      - name: Check markdown links with lychee
        uses: lycheeverse/lychee-action@v2.7.0
        with:
          # Use simplified configuration for reliability
          args: >-
            --config config/lychee.toml
            --no-progress
            --cache
            --max-cache-age 1d
            "docs/**/*.md"
            "README.md"
          # Don't fail the entire pipeline on link check failures
          fail: false
          jobSummary: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Report link check results
        if: always()
        run: |
          echo "üìã Link validation completed (non-blocking)"
          echo "‚ÑπÔ∏è  Check job summary for detailed results"

  # Job 4: Simple YAML Validation (Quiet)
  yaml-validation:
    name: YAML Syntax Check
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Install yamllint
        run: python3 -m pip install yamllint

      - name: Validate workflow files only
        run: |
          echo "üîç Validating critical YAML files..."
          if ! python3 -m yamllint -c config/.yamllint.yml .github/workflows/; then
            echo "‚ùå YAML validation failed"
            echo "‚ÑπÔ∏è  Check yamllint output above for details"
            exit 1
          fi
          echo "‚úÖ YAML validation completed"

